{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db07ea2",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Random Forest is a trademark term for an ensemble of decision trees. In Random Forest, we’ve collection of decision trees (so known as “Forest”). To classify a new object based on attributes, each tree gives a classification and we say the tree “votes” for that class. The forest chooses the classification having the most votes (over all the trees in the forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6e741",
   "metadata": {},
   "source": [
    "\"Random Forest is a classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset.\" Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, and it predicts the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b435b2",
   "metadata": {},
   "source": [
    "- The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80830624",
   "metadata": {},
   "source": [
    "![](r1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76004c1e",
   "metadata": {},
   "source": [
    "Assumptions for Random Forest\n",
    "- Since the random forest combines multiple trees to predict the class of the dataset, it is possible that some decision trees may predict the correct output, while others may not. But together, all the trees predict the correct output. Therefore, below are two assumptions for a better Random forest classifier:\n",
    "\n",
    "- There should be some actual values in the feature variable of the dataset so that the classifier can predict accurate results rather than a guessed result.\n",
    "-The predictions from each tree must have very low correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06c9e4",
   "metadata": {},
   "source": [
    "Below are some points that explain why we should use the Random Forest algorithm:\n",
    "\n",
    "- It takes less training time as compared to other algorithms.\n",
    "- It predicts output with high accuracy, even for the large dataset it runs efficiently.\n",
    "- It can also maintain accuracy when a large proportion of data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262bd33",
   "metadata": {},
   "source": [
    "Random Forest works in two-phase first is to create the random forest by combining N decision tree, and second is to make predictions for each tree created in the first phase.\n",
    "\n",
    "\n",
    "The Working process can be explained in the below steps and diagram:\n",
    "\n",
    "- Step-1: Select random K data points from the training set.\n",
    "\n",
    "- Step-2: Build the decision trees associated with the selected data points (Subsets).\n",
    "\n",
    "- Step-3: Choose the number N for decision trees that you want to build.\n",
    "\n",
    "- Step-4: Repeat Step 1 & 2.\n",
    "\n",
    "- Step-5: For new data points, find the predictions of each decision tree, and assign the new data points to the category that wins the majority votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac64aa7",
   "metadata": {},
   "source": [
    "Example: \n",
    "- Suppose there is a dataset that contains multiple fruit images. So, this dataset is given to the Random forest classifier. The dataset is divided into subsets and given to each decision tree. During the training phase, each decision tree produces a prediction result, and when a new data point occurs, then based on the majority of results, the Random Forest classifier predicts the final decision. Consider the below image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4bb89d",
   "metadata": {},
   "source": [
    "![](r2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc44354",
   "metadata": {},
   "source": [
    "There are mainly four sectors where Random forest mostly used:\n",
    "\n",
    "- Banking: Banking sector mostly uses this algorithm for the identification of loan risk.\n",
    "- Medicine: With the help of this algorithm, disease trends and risks of the disease can be identified.\n",
    "- Land Use: We can identify the areas of similar land use by this algorithm.\n",
    "- Marketing: Marketing trends can be identified using this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1864484",
   "metadata": {},
   "source": [
    "Advantages of Random Forest\n",
    "- Random Forest is capable of performing both Classification and Regression tasks.\n",
    "- It is capable of handling large datasets with high dimensionality.\n",
    "- It enhances the accuracy of the model and prevents the overfitting issue.\n",
    "\n",
    "\n",
    "Disadvantages of Random Forest\n",
    "- Although random forest can be used for both classification and regression tasks, it is not more suitable for Regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d2c24",
   "metadata": {},
   "source": [
    "Implementation Steps are given below:\n",
    "\n",
    "- Data Pre-processing step\n",
    "- Fitting the Random forest algorithm to the Training set\n",
    "- Predicting the test result\n",
    "- Test accuracy of the result (Creation of Confusion matrix)\n",
    "- Visualizing the test set result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6280572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56eae083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temp humidity    wind decision\n",
       "0     sunny   hot     high    weak       no\n",
       "1     sunny   hot     high  strong       no\n",
       "2  overcast   hot     high    weak      yes\n",
       "3      rain  mild     high    weak      yes\n",
       "4      rain  cool   normal    weak      yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing datasets \n",
    "data = pd.read_csv('d:gini_index.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65da4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data in numeric form\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in data.columns:\n",
    "    data[i]=le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3a9714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlook  temp  humidity  wind  decision\n",
       "0        2     1         0     1         0\n",
       "1        2     1         0     0         0\n",
       "2        0     1         0     1         1\n",
       "3        1     2         0     1         1\n",
       "4        1     0         1     1         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac11ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Independent and dependent Variable  \n",
    "x = data.drop('decision',axis=1)\n",
    "y = data['decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ee3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35384418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# festure scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st_x = StandardScaler()\n",
    "x_train = st_x.fit_transform(x_train)\n",
    "x_test = st_x.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ba8a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest classifier to the training set  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=10,criterion='entropy')\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec569e7",
   "metadata": {},
   "source": [
    "- n_estimators= The required number of trees in the Random Forest. The default value is 10. We can choose any number but need to take care of the overfitting issue.\n",
    "- criterion= It is a function to analyze the accuracy of the split. Here we have taken \"entropy\" for the information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0682a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set result  \n",
    "y_pred = model.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0750c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the Confusion matrix  \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376ba52",
   "metadata": {},
   "source": [
    "### Difference b/w Decission tree and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08385148",
   "metadata": {},
   "source": [
    "Decision trees\n",
    "1. Decision trees normally suffer from the problem of overfitting if it’s allowed to grow without any control\n",
    "2. A single decision tree is faster in computation.\n",
    "3. When a data set with features is taken as input by a decision tree it will formulate some set of rules to do prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb717f",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "1. Random forests are created from subsets of data and the final output is based on average or majority ranking and hence the problem of overfitting is taken care of.\n",
    "2. It is comparatively slower.\n",
    "3. Random forest randomly selects observations, builds a decision tree and the average result is taken. It doesn’t use any set of formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02aecd",
   "metadata": {},
   "source": [
    "Following hyperparameters increases the predictive power:\n",
    "\n",
    "1. n_estimators– number of trees the algorithm builds before averaging the predictions.\n",
    "\n",
    "2. max_features– maximum number of features random forest considers splitting a node.\n",
    "\n",
    "3. mini_sample_leaf– determines the minimum number of leaves required to split an internal node.\n",
    "\n",
    "Following hyperparameters increases the speed:\n",
    "\n",
    "1. n_jobs– it tells the engine how many processors it is allowed to use. If the value is 1, it can use only one processor but if the value is -1 there is no limit.\n",
    "\n",
    "2. random_state– controls randomness of the sample. The model will always produce the same results if it has a definite value of random state and if it has been given the same hyperparameters and the same training data.\n",
    "\n",
    "3. oob_score – OOB means out of the bag. It is a random forest cross-validation method. In this one-third of the sample is not used to train the data instead used to evaluate its performance. These samples are called out of bag samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec653b",
   "metadata": {},
   "source": [
    "![](rf1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df82650",
   "metadata": {},
   "source": [
    "![](rf2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e176c",
   "metadata": {},
   "source": [
    "![](rf3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cabf98",
   "metadata": {},
   "source": [
    "![](rf4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445fb45",
   "metadata": {},
   "source": [
    "### By Nikhil Yadav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
